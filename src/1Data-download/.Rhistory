library(googledrive)
drive_deauth()
drive_user()
public_file <-  drive_get(as_id("10HsGspftDNgq-fjAjeUwB8QsmHZWUJyT"))
drive_download(public_file, path = paste0(outdir, "/Ecological_and_Feed_Distribution.zip"), overwrite = TRUE)
drive_download(public_file, path = paste0(outdir, "/Ecological_and_Feed_Distribution.zip"), overwrite = TRUE)
unzip(zipfile = paste0(outdir, "/Ecological_and_Feed_Distribution.zip"), exdir = paste0(outdir, "/"))
unzip(zipfile = paste0(outdir, "/Ecological_and_Feed_Distribution.zip"), exdir = paste0(outdir, "/"))
library(RCurl)
outdir <- paste0(root, "/Day_1/SpatialData/inputs/Feed/LandUse"); dir.create(outdir, F, T)
# Land use classes of interest
land_use_classes <- c("Tree", "Grass", "Crops", "Shrub")
# Download the file
lapply(land_use_classes, function(land_use_class){
if (!file.exists(paste0(outdir, "/PROBAV_LC100_global_v3.0.1_2019-nrt_", land_use_class, "-CoverFraction-layer_EPSG-4326.tif"))){
cat("Downloading: ", land_use_class, "\n")
download.file(
url = paste0("https://zenodo.org/records/3939050/files/PROBAV_LC100_global_v3.0.1_2019-nrt_", land_use_class, "-CoverFraction-layer_EPSG-4326.tif"),
destfile = paste0(outdir, "/PROBAV_LC100_global_v3.0.1_2019-nrt_", land_use_class, "-CoverFraction-layer_EPSG-4326.tif"), quiet = TRUE)
}else{
cat("File already exists: ", land_use_class, "\n")
}
})
library(RCurl)
outdir <- paste0(root, "/Day_1/SpatialData/inputs/TreeCover"); dir.create(outdir, F, T)
if (!file.exists(paste0(outdir, "/ps_africa_treecover_2019_100m_v1.0.tif"))){
cat("Downloading ", "tree cover", "\n")
download.file(
url = paste0("https://zenodo.org/records/7764460/files/ps_africa_treecover_2019_100m_v1.0.tif"),
destfile = paste0(outdir, "/ps_africa_treecover_2019_100m_v1.0.tif"), quiet = TRUE)
}else{
cat("File already exists: ", "tree cover", "\n")
}
library(RCurl)
outdir <- paste0(root, "/Day_1/SpatialData/inputs/Feed/CropType"); dir.create(outdir, F, T)
#Libraries
library(RCurl)
options(timeout = 3600)
outdir <- paste0(root, "/Day_1/SpatialData/inputs/ProtectedAreas"); dir.create(outdir, F, T)
library(RCurl)
outdir <- paste0("/Day_1/SpatialData/inputs/Feed/DMP"); dir.create(outdir, F, T)
paste0("/Day_1/SpatialData/inputs/Feed/DMP")
outdir <- paste0(root, "/Day_1/SpatialData/inputs/Feed/DMP"); dir.create(outdir, F, T)
library(httr)
library(rvest)
yearList <- c("2020", "2021", "2022", "2023")
year <- yearList[]
outdir <- paste0(root, "/Day_1/SpatialData/inputs/PhenologyModis/", year); dir.create(outdir, F, T)
outdir <- paste0(root, "/Day_1/SpatialData/inputs/PhenologyModis/", year); dir.create(outdir, F, T)
year <- "2020"
outdir <- paste0(root, "/Day_1/SpatialData/inputs/PhenologyModis/", year); dir.create(outdir, F, T)
outdir <- paste0(root, "/Day_1/SpatialData/inputs/Burned/", year); dir.create(outdir, F, T)
library(googledrive)
outdir <- paste0(root, "/Day_1/Tables/inputs/CropParams"); dir.create(outdir, F, T)
drive_deauth()
drive_user()
#folder link to id
public_folder = "https://drive.google.com/drive/folders/1SpB1p9i4MGU1gMahF4M3Uc-HZr8FGoqd"
folder_id = drive_get(as_id(public_folder))
#find files in folder
public_files = drive_ls(folder_id)
for(i in seq_along(public_files)){
public_file <- public_files[i, ]
file_name <- public_file$name
drive_download(public_file, path = paste0(outdir, "/", file_name), overwrite = TRUE)
}
library(tidyverse)
library(tidyverse)
library(rvest)
outdir <- paste0(root, "/Day_1/Tables/inputs/CropParams"); dir.create(outdir, F, T)
library(RCurl)
outdir <- paste0(root, "/Day_1/SpatialData/inputs/GLW4"); dir.create(outdir, F, T)
speciesCategories <- c("CTL", "GTS", "SHP", "PGS")
outdir <- paste0(root, "/Day_1/Tables/inputs/LivestockParams"); dir.create(outdir, F, T)
drive_deauth()
drive_user()
#folder link to id
public_folder = "https://drive.google.com/drive/folders/1-3N_kmMgcHr_tayylSxlMJAr-2PBGFXd"
folder_id = drive_get(as_id(public_folder))
#find files in folder
public_files = drive_ls(folder_id)
for(i in seq_along(public_files)){
public_file <- public_files[i, ]
file_name <- public_file$name
drive_download(public_file, path = paste0(outdir, "/", file_name), overwrite = TRUE)
}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, tidy.opts=list(width.cutoff=60), tidy=TRUE)
library(sf)
indir <- paste0(root, "/Day_1/SpatialData/inputs/AdminBound")
aoi1 <- read_sf(paste0(indir, "/gadm40_BFA_1.shp"))
knitr::opts_chunk$set(warning = FALSE, message = FALSE, tidy.opts=list(width.cutoff=60), tidy=TRUE)
root <- "/home/s2255815/rdrive/AU_IBAR/Feed-balance-modeling-training"
library(RCurl)
options(timeout=3600)
outdir <- paste0(root, "/Day_1/SpatialData/inputs/Feed/DMP"); dir.create(outdir, F, T)
# Download manifest
download.file(
url <- "https://globalland.vito.be/download/manifest/dmp_300m_v1_10daily_netcdf/manifest_clms_global_dmp_300m_v1_10daily_netcdf_latest.txt",
destfile = paste0(outdir, "/manifest_clms_global_dmp_300m_v1_10daily_netcdf_latest.txt"))
# Read in manifest
dmp_manifest <- readLines(paste0(outdir, "/manifest_clms_global_dmp_300m_v1_10daily_netcdf_latest.txt"))
# Combine the patterns to search for
patterns <- "RT5_2020|RT6_2020|RT6_2021|RT2_202211100000|RT2_202211200000|RT2_202211300000|RT2_202212100000|RT2_202212200000|RT2_202212310000|RT6_2022|RT6_2023"
# Use grep to search for any of the patterns in dmp_manifest
dmp_manifest_list <- grep(patterns, dmp_manifest, value=TRUE) #select a file for each day
# Define files to exclude
exclude_patterns <- "RT5_202007100000|RT5_202007200000|RT5_202007310000|RT5_202008100000|RT5_202008200000|RT5_202008310000|RT6_202211100000|RT6_202211200000"
# Exclude the specific files from the results
dmp_manifest_list <- grep(exclude_patterns, dmp_manifest_list, invert=TRUE, value=TRUE)
dmp_manifest_list
dmp_manifest_list
dmp_selected <- grep("202001100000|202001200000|202001310000", dmp_manifest_list, invert=TRUE, value=TRUE)
dmp_selected
# Exclude the specific files from the results
dmp_manifest_list <- grep(exclude_patterns, dmp_manifest_list, invert=TRUE, value=TRUE)
dmp_selected <- grep("202001100000|202001200000|202001310000", dmp_manifest_list, invert=TRUE, value=TRUE)
dmp_selected
dmp_selected <- grep("202001100000|202001200000|202001310000", dmp_manifest_list)
dmp_selected <- grep("202001100000|202001200000|202001310000", dmp_manifest_list, value=TRUE)
dmp_selected
i<-1
file_name_base <- basename(i)
i<-dmp_selected[1]
file_name_base <- basename(i)
filenamep1 <- substr(file_name_base, 1, 13)
filenamep2 <- substr(file_name_base, 18, 29)
file_name <- paste0(filenamep1, "RT6_", filenamep2, "_GLOBE_OLCI_V1.1.2.nc")
paste0(outdir, "/", file_name)
if(!file.exists(paste0(outdir, "/", file_name))){
cat("Downloading: ", file_name, "\n")
download.file(url = i, destfile = paste0(outdir, "/", file_name))
}else {
cat("File already exists: ", file_name, "\n")
}
for (i in dmp_selected){
# Extract the file name
#file_name <- basename(sub("OLCI_V1.*", "OLCI_V1", i))
file_name_base <- basename(i)
filenamep1 <- substr(file_name_base, 1, 13)
filenamep2 <- substr(file_name_base, 18, 29)
file_name <- paste0(filenamep1, "RT6_", filenamep2, "_GLOBE_OLCI_V1.1.2.nc")
if(!file.exists(paste0(outdir, "/", file_name))){
cat("Downloading: ", file_name, "\n")
download.file(url = i, destfile = paste0(outdir, "/", file_name))
}else {
cat("File already exists: ", file_name, "\n")
}
}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, tidy.opts=list(width.cutoff=60), tidy=TRUE)
# Load required packages
library(knitr)
library(kableExtra)
library(formatR)
# Read the CSV file
input_data <- read.csv("/home/s2255815/rdrive/AU_IBAR/ruminant-feed-balance/src/1Data-download/input_data.csv")
# Display the table with bold headers
input_data %>%
kable(format = "latex", longtable = TRUE, booktabs = TRUE) %>%
kable_styling(latex_options = c("hold_position"), font_size = 10) %>%  # Increase font size
row_spec(0, bold = TRUE) %>%   # Make header bold
landscape() %>%
column_spec(1:ncol(input_data), width = "3cm")
root <- "/home/s2255815/rdrive/AU_IBAR/Feed-balance-modeling-training"
library(geodata)
library(sf)
outdir <- paste0(root, "/Day_1/SpatialData/inputs/AdminBound"); dir.create(outdir, F, T)
admin_levels <- c("0", "1", "2")
for(admin_level in admin_levels){
aoi <- geodata::gadm(country = "NGA", level=admin_level, path = paste0(outdir), version="latest") %>% sf::st_as_sf()
write_sf(aoi, paste0(outdir, "/gadm40_BFA_", admin_level, ".shp"), append = FALSE)
}
library(RCurl)
library(sf)
outdir <- paste0(root, "/Day_1//SpatialData/inputs/AggregationZones"); dir.create(outdir, F, T)
download.file(
url = paste0("https://shapefiles.fews.net/LHZ/NG_LHZ_2018.zip"),
destfile = paste0(outdir, "/NG_LHZ_2018.zip"), quiet = TRUE)
unzip(zipfile = paste0(outdir, "/NG_LHZ_2018.zip"), exdir = paste0(outdir, "/"))
# Other zonations maps
library(googledrive)
drive_deauth()
drive_user()
public_file <-  drive_get(as_id("10HsGspftDNgq-fjAjeUwB8QsmHZWUJyT"))
drive_download(public_file, path = paste0(outdir, "/Ecological_and_Feed_Distribution.zip"), overwrite = TRUE)
unzip(zipfile = paste0(outdir, "/Ecological_and_Feed_Distribution.zip"), exdir = paste0(outdir, "/"))
knitr::opts_chunk$set(warning = FALSE, message = FALSE, tidy.opts=list(width.cutoff=60), tidy=TRUE)
# read AOI
aoi <- read_sf(paste0(root, "/Day_1/SpatialData/inputs/AdminBound/aoi0.shp"))
aste0(root, "/Day_1/SpatialData/inputs/Feed_DrySeason/DMP")
paste0(root, "/Day_1/SpatialData/inputs/Feed_DrySeason/DMP")
paste0(root, "/Day_1/SpatialData/inputs/Feed_DrySeason/DMP")
# output folder
outdir <- paste0(root, "/Day_2/SpatialData/inputs/Feed_DrySeason/DMP"); dir.create(outdir, F, T)
nc_files <- list.files(root, "/Day_1/SpatialData/inputs/Feed/DMP", pattern = ".nc$", full.names = TRUE, recursive = TRUE)
paste0(root, "/Day_1/SpatialData/inputs/Feed/DMP")
nc_files <- list.files(paste0(root, "/Day_1/SpatialData/inputs/Feed/DMP"), pattern = ".nc$", full.names = TRUE, recursive = TRUE)
nc_name <- gsub('.{3}$', '', basename(nc_file))
nc_file <- nc_files[1]
nc_name <- gsub('.{3}$', '', basename(nc_file))
iDMP <- raster::raster(nc_file, varname="DMP", ncdf=TRUE)
iDMP <- crop(iDMP, extent(aoi))
iDMP <- mask(iDMP, aoi)
paste0(outdir, "/", nc_name, ".tif")
# save as GeoTIFF
raster::writeRaster(iDMP, filename = paste0(outdir, "/", nc_name, ".tif"), overwrite=TRUE)
library(ncdf4) # package for netcdf manipulation
library(raster) # package for raster manipulation
library(dplyr)
library(rgdal)
library(sf)
# read AOI
aoi <- read_sf(paste0(root, "/Day_1/SpatialData/inputs/AdminBound/gadm40_BFA_0.shp"))
nc_files <- list.files(paste0(root, "/Day_1/SpatialData/inputs/Feed/DMP"), pattern = ".nc$", full.names = TRUE, recursive = TRUE)
nc_files
root
nc_data <- nc_open(paste0(root, "/Day_1/SpatialData/inputs/Feed/DMP/c_gls_DMP300-RT6_202001100000_GLOBE_OLCI_V1.1.2.nc"))
nc_data
nc_data
nc_close(nc_data)
nc_close(nc_file)
nc_file <- nc_open(paste0(root, "/Day_1/SpatialData/inputs/Feed/DMP/c_gls_DMP300-RT6_202001100000_GLOBE_OLCI_V1.1.2.nc"))
nc_file
nc_close(nc_file)
nc_file <- nc_files[1]
nc_name <- gsub('.{3}$', '', basename(nc_file))
iDMP <- raster::raster(nc_file, varname="DMP", ncdf=TRUE)
iDMP <- crop(iDMP, extent(aoi))
iDMP <- crop(iDMP, extent(aoi))
iDMP <- mask(iDMP, aoi)
paste0(outdir, "/", nc_name, ".tif")
for (nc_file in nc_files){
nc_name <- gsub('.{3}$', '', basename(nc_file))
iDMP <- raster::raster(nc_file, varname="DMP", ncdf=TRUE)
iDMP <- crop(iDMP, extent(aoi))
iDMP <- mask(iDMP, aoi)
# save as GeoTIFF
raster::writeRaster(iDMP, filename = paste0(outdir, "/", nc_name, ".tif"), overwrite=TRUE)
}
plot(iDMP)
aoi
library(tidyterra)
ggplot() + geom_sf(data = aoi, colour = "black", show.legend = F) +
geom_spatraster(data = iDMP) +
geom_sf(data = aoi1, colour = "black", fill = NA, show.legend = F) +
scale_fill_gradient(low = "#CDDF4A", high = "#0BAE1C", na.value = NA, name="DM kg/ha")
library(tidyterra)
ggplot() + geom_sf(data = aoi, colour = "black", show.legend = F) +
geom_spatraster(data = iDMP %>% rast()) +
geom_sf(data = aoi1, colour = "black", fill = NA, show.legend = F) +
scale_fill_gradient(low = "#CDDF4A", high = "#0BAE1C", na.value = NA, name="DM kg/ha")
root <- "/home/s2255815/rdrive/AU_IBAR/Feed-balance-modeling-training"
library(RCurl)
outdir <- paste0(root, "/Day_1/SpatialData/inputs/Feed/CropType"); dir.create(outdir, F, T)
download.file(
url = paste0("https://www.dropbox.com/scl/fo/808qb807xw4olh8z5pagd/APYE4A4ApAbKhlcfWspRxcg/Global_Geotiff?e=1&file_subpath=%2Fspam2020V0r1_global_harvested_area&preview=spam2020V0r1_global_harvested_area.zip&rlkey=mkmj10j7ub49dzrqo4qec25gp&subfolder_nav_tracking=1&st=34q63fux&dl=1"),
destfile = paste0(outdir, "/spam2020V1r0_global.zip"), quiet = TRUE)
# Unzip the downloaded file (only the specific zip inside the archive)
unzip(zipfile = paste0(outdir, "/spam2020V1r0_global.zip"),
files = "spam2020V0r1_global_physical_area.zip",
exdir = paste0(outdir))
# List all files in the folder
all_files <- list.files(paste0(outdir), full.names = TRUE)
all_files
# Identify files to remove (all files except the one to keep)
files_to_remove <- all_files[!basename(all_files) %in% "spam2020V0r1_global_physical_area.zip"]
# Remove the files
file.remove(files_to_remove)
# List all files in the folder
all_files <- list.files(paste0(outdir), full.names = TRUE)
all_files
# Unzip the second archive
unzip(zipfile = paste0(outdir, "/spam2020V0r1_global_physical_area.zip"),
exdir = paste0(outdir, "/"))
# List all files in the folder
cropPhysicalArea <- list.files(paste0(outdir, "/spam2020V0r1_global_physical_area"), full.names = TRUE)
cropPhysicalArea
basename(cropPhysicalArea)
cropPhysicalArea_to_remove <- grep("BEAN|MAIZ", cropPhysicalArea, invert = TRUE, value = TRUE)
cropPhysicalArea_to_remove
# Remove all files except beans and maize
file.remove(cropPhysicalArea_to_remove)
root <- "/home/s2255815/rdrive/AU_IBAR/Feed-balance-modeling-training"
# output folder
outdir <- paste0(root, "/Day_1/SpatialData/inputs/SPAM2020"); dir.create(outdir, F, T)
# output folder
outdir <- paste0(root, "/Day_2/SpatialData/inputs/SPAM2020"); dir.create(outdir, F, T)
aoi
root
dmpTemp <- rast(paste0(root, "/Day_2/SpatialData/inputs/Feed_DrySeason/DMP/c_gls_DMP300-RT6_202001100000_GLOBE_OLCI_V1.1.2.tif"))
dmpTemp
# output folder
outdir <- paste0(root, "/Day_2/SpatialData/inputs/SPAM2020"); dir.create(outdir, F, T)
dmpTemp <- rast(paste0(root, "/Day_2/SpatialData/inputs/Feed_DrySeason/DMP/c_gls_DMP300-RT6_202001100000_GLOBE_OLCI_V1.1.2.tif"))
sPamfiles <- list.files(paste0(root, "/Day_1/SpatialData/inputs/Feed/CropType/spam2020V0r1_global_physical_area"), pattern = "_A.tif$", full.names = TRUE, recursive = TRUE)
sPamfiles
sPamfile <- sPamfiles[1]
sPamfile_name <- tolower(gsub('.{4}$', '', basename(sPamfile)))
isPamFile <- rast(sPamfile)
isPamFile <- crop(isPamFile, ext(dmpTemp))
isPamFile <- resample(isPamFile, dmpTemp, method="bilinear")
isPamFile <- resample(isPamFile, dmpTemp, method="bilinear")
isPamFile <- mask(isPamFile, mask = dmpTemp)
isPamFile[is.nan(values(isPamFile))] <- NA
isPamFile[is.nan(values(isPamFile))] <- NA
names(isPamFile) <- sPamfile_name
isPamFile[is.nan(values(isPamFile))] <- NA
names(isPamFile) <- sPamfile_name
varnames(isPamFile) <- sPamfile_name
paste0(outdir, "/", sPamfile_name, ".tif")
lapply(sPamfiles, function(sPamfile){
sPamfile_name <- tolower(gsub('.{4}$', '', basename(sPamfile)))
isPamFile <- rast(sPamfile)
isPamFile <- crop(isPamFile, ext(dmpTemp))
isPamFile <- resample(isPamFile, dmpTemp, method="bilinear")
isPamFile <- mask(isPamFile, mask = dmpTemp)
isPamFile[is.nan(values(isPamFile))] <- NA
names(isPamFile) <- sPamfile_name
varnames(isPamFile) <- sPamfile_name
# save as GeoTIFF
terra::writeRaster(isPamFile, filename = paste0(outdir, "/", sPamfile_name, ".tif"), overwrite=TRUE)
})
knitr::opts_chunk$set(warning = FALSE, message = FALSE, tidy.opts=list(width.cutoff=60), tidy=TRUE)
root <- "/home/s2255815/rdrive/AU_IBAR/Feed-balance-modeling-training"
library(ncdf4) # package for netcdf manipulation
library(raster) # package for raster manipulation
library(dplyr)
library(rgdal)
library(sf)
# output folder
outdir <- paste0(root, "/Day_2/SpatialData/inputs/Feed_DrySeason/DMP"); dir.create(outdir, F, T)
# read AOI
aoi <- read_sf(paste0(root, "/Day_1/SpatialData/inputs/AdminBound/gadm40_BFA_0.shp"))
nc_files <- list.files(paste0(root, "/Day_1/SpatialData/inputs/Feed/DMP"), pattern = ".nc$", full.names = TRUE, recursive = TRUE)
nc_files
nc_file <- nc_open(paste0(root, "/Day_1/SpatialData/inputs/Feed/DMP/c_gls_DMP300-RT6_202001100000_GLOBE_OLCI_V1.1.2.nc"))
nc_file
nc_close(nc_file)
lapply(nc_files, function(nc_file){
nc_name <- gsub('.{3}$', '', basename(nc_file))
iDMP <- raster::raster(nc_file, varname="DMP", ncdf=TRUE)
iDMP <- crop(iDMP, extent(aoi))
iDMP <- mask(iDMP, aoi)
# save as GeoTIFF
raster::writeRaster(iDMP, filename = paste0(outdir, "/", nc_name, ".tif"), overwrite=TRUE)
})
library(tidyterra)
library(ggplot2)
library(terra)
ggplot() + geom_sf(data = aoi, colour = "black", show.legend = F) +
geom_spatraster(data = iDMP %>% rast()) +
geom_sf(data = aoi, colour = "black", fill = NA, show.legend = F) +
scale_fill_gradient(low = "#CDDF4A", high = "#0BAE1C", na.value = NA, name="DM (kg/hectare/day)")
# output folder
outdir <- paste0(root, "/Day_2/SpatialData/inputs/SPAM2020"); dir.create(outdir, F, T)
dmpTemp <- rast(paste0(root, "/Day_2/SpatialData/inputs/Feed_DrySeason/DMP/c_gls_DMP300-RT6_202001100000_GLOBE_OLCI_V1.1.2.tif"))
sPamfiles <- list.files(paste0(root, "/Day_1/SpatialData/inputs/Feed/CropType/spam2020V0r1_global_physical_area"), pattern = "_A.tif$", full.names = TRUE, recursive = TRUE)
lapply(sPamfiles, function(sPamfile){
sPamfile_name <- tolower(gsub('.{4}$', '', basename(sPamfile)))
isPamFile <- rast(sPamfile)
isPamFile <- crop(isPamFile, ext(dmpTemp))
isPamFile <- resample(isPamFile, dmpTemp, method="bilinear")
isPamFile <- mask(isPamFile, mask = dmpTemp)
isPamFile[is.nan(values(isPamFile))] <- NA
names(isPamFile) <- sPamfile_name
varnames(isPamFile) <- sPamfile_name
# save as GeoTIFF
writeRaster(isPamFile, filename = paste0(outdir, "/", sPamfile_name, ".tif"), overwrite=TRUE)
})
knitr::opts_chunk$set(warning = FALSE, message = FALSE, tidy.opts=list(width.cutoff=60), tidy=TRUE)
root <- "/home/s2255815/rdrive/AU_IBAR/Feed-balance-modeling-training"
library(ncdf4) # package for netcdf manipulation
library(raster) # package for raster manipulation
library(dplyr)
library(rgdal)
library(sf)
# output folder
outdir <- paste0(root, "/Day_2/SpatialData/inputs/Feed_DrySeason/DMP"); dir.create(outdir, F, T)
# read AOI
aoi <- read_sf(paste0(root, "/Day_1/SpatialData/inputs/AdminBound/gadm40_BFA_0.shp"))
nc_files <- list.files(paste0(root, "/Day_1/SpatialData/inputs/Feed/DMP"), pattern = ".nc$", full.names = TRUE, recursive = TRUE)
nc_files
nc_file <- nc_open(paste0(root, "/Day_1/SpatialData/inputs/Feed/DMP/c_gls_DMP300-RT6_202001100000_GLOBE_OLCI_V1.1.2.nc"))
nc_file
nc_close(nc_file)
nc_close(nc_file)
knitr::opts_chunk$set(warning = FALSE, message = FALSE, tidy.opts=list(width.cutoff=60), tidy=TRUE)
root <- "/home/s2255815/rdrive/AU_IBAR/Feed-balance-modeling-training"
library(ncdf4) # package for netcdf manipulation
library(raster) # package for raster manipulation
library(dplyr)
library(rgdal)
library(sf)
# output folder
outdir <- paste0(root, "/Day_2/SpatialData/inputs/Feed_DrySeason/DMP"); dir.create(outdir, F, T)
# read AOI
aoi <- read_sf(paste0(root, "/Day_1/SpatialData/inputs/AdminBound/gadm40_BFA_0.shp"))
nc_files <- list.files(paste0(root, "/Day_1/SpatialData/inputs/Feed/DMP"), pattern = ".nc$", full.names = TRUE, recursive = TRUE)
nc_files
nc_file <- nc_open(paste0(root, "/Day_1/SpatialData/inputs/Feed/DMP/c_gls_DMP300-RT6_202001100000_GLOBE_OLCI_V1.1.2.nc"))
nc_file
iDMP
paste0(outdir, "/", nc_name, ".tif")
root
iDMP <- rast(paste0(root, "/Day_2/SpatialData/inputs/Feed_DrySeason/DMP/c_gls_DMP300-RT6_202001310000_GLOBE_OLCI_V1.1.2.tif"))
ggplot() + geom_sf(data = aoi, colour = "black", show.legend = F) +
geom_spatraster(data = iDMP %>% rast()) +
geom_sf(data = aoi, colour = "black", fill = NA, show.legend = F) +
scale_fill_gradient(low = "#CDDF4A", high = "#0BAE1C", na.value = NA, name="DM (kg/hectare/day)")
iDMP
iDMP <- rast(paste0(root, "/Day_2/SpatialData/inputs/Feed_DrySeason/DMP/c_gls_DMP300-RT6_202001310000_GLOBE_OLCI_V1.1.2.tif"))
ggplot() + geom_sf(data = aoi, colour = "black", show.legend = F) +
geom_spatraster(data = iDMP) +
geom_sf(data = aoi, colour = "black", fill = NA, show.legend = F) +
scale_fill_gradient(low = "#CDDF4A", high = "#0BAE1C", na.value = NA, name="DM (kg/hectare/day)")
library(ncdf4) # package for netcdf manipulation
library(dplyr)
library(rgdal)
library(sf)
library(tidyterra)
library(ggplot2)
library(terra)
library(readr)
root
root <- "/home/s2255815/rdrive/AU_IBAR/Feed-balance-modeling-training"
root
#setwd("/exports/eddie/scratch/sfraval/feed-surfaces/")
cropHI <- read_csv(paste0(root, "/Day_2/Tables/crop_harvest index.csv"))
pathSPAM <- paste0(root, "/Day_2/SpatialData/inputs/SPAM2020")
pathSPAMInter <- paste0(root, "/Day_2/SpatialData/inputs/SPAM2020/intermediate"); dir.create(pathSPAMInter, F, T)
filesSPAM <- list.files(path = pathSPAM, pattern = "_a.tif$", full.names = T)
stSPAM <- rast(filesSPAM)
crops <-sub(".*_a_(.*?)_a\\.tif$", "\\1", filesSPAM)
crops
tmpCropIndex <- grep(pattern = paste(crops, collapse = "|"), names(stSPAM))
tmpCropIndex
iSPAMcropArea <- app(rast(stSPAM[[tmpCropIndex]]), fun = sum, na.rm = TRUE)
iSPAMcropArea
plot(iSPAMcropArea)
filesSPAM <- list.files(path = pathSPAM, pattern = "_a.tif$", full.names = T)
stSPAM <- rast(filesSPAM)
plot(stSPAM)
iSPAMcropArea <- app(stSPAM, fun = sum, na.rm = TRUE)
iSPAMcropArea
plot(iSPAMcropArea)
I<-1
i<-1
tmpCropIndex <- grep(pattern = paste(crops[i], collapse = "|"), names(stSPAM))
tmpCropIndex
iSPAMtmpArea <- stSPAM[[tmpCropIndex]]
iSPAMtmpArea
icrop[icrop >0] <- (1 - cropHI$harvest_index[cropHI$codeSPAM == crops[i]])
icrop <- stSPAM[[tmpCropIndex]]
icrop[icrop >0] <- (1 - cropHI$harvest_index[cropHI$codeSPAM == crops[i]])
icrop
i
paste0(pathSPAMInter, "/", names(icrop), "_res_frac.tif")
i
crops[i]
paste0(pathSPAMInter, "/", crops[i], "_res_frac.tif")
# Calculate crop proportion
stSPAMcropProp <- app(iSPAMtmpArea, iSPAMcropArea, fun = function(x, y){(x/y)}, na.rm=TRUE)
# Calculate crop proportion
stSPAMcropProp <- iSPAMtmpArea/iSPAMcropArea
stSPAMcropProp
crop <- crops[1]
# Get index for the current crop in stSPAM
tmpCropIndex <- grep(pattern = crop, names(stSPAM))
tmpCropIndex
paste0(pathSPAMInter, "/", crops[i], "_prop.tif")
```{r}
for(i in 1: length(crops)){
# Extract the relevant SPAM data for the crop
tmpCropIndex <- grep(pattern = paste(crops[i], collapse = "|"), names(stSPAM))
iSPAMtmpArea <- stSPAM[[tmpCropIndex]]
# Adjust crop data based on the harvest index
icrop <- stSPAM[[tmpCropIndex]]
icrop[icrop >0] <- (1 - cropHI$harvest_index[cropHI$codeSPAM == crops[i]])
# Write the adjusted crop data
writeRaster(icrop, paste0(pathSPAMInter, "/", crops[i], "_res_frac.tif"), overwrite = T)
# Calculate crop proportion and write the output
stSPAMcropProp <- iSPAMtmpArea/iSPAMcropArea
writeRaster(icrop, paste0(pathSPAMInter, "/", crops[i], "_prop.tif"), overwrite = T)
}
paste0(pathSPAMInter, "/", crops[i], "_prop.tif")
pathSPAMInter
i<-crops[1]
crop_res <- rast(paste0(pathSPAMInter, "/", i, "_prop.tif"))
crop_res
crop_res <- rast(paste0(pathSPAMInter, "/", i, "_res_frac.tif"))
crop_prop <- rast(paste0(pathSPAMInter, "/", i, "_prop.tif"))
crop_res_weighted <- weighted.mean(crop_res, crop_prop, na.rm = T)
crop_res_weighted
i<-2
crop_res <- rast(paste0(pathSPAMInter, "/", i, "_res_frac.tif"))
crop_prop <- rast(paste0(pathSPAMInter, "/", i, "_prop.tif"))
crop_res_weighted <- weighted.mean(crop_res, crop_prop, na.rm = T)
crop_res_weighted
i<-crops[2]
i<-crops[1]
i<-crops[2]
crop_res <- rast(paste0(pathSPAMInter, "/", i, "_res_frac.tif"))
crop_prop <- rast(paste0(pathSPAMInter, "/", i, "_prop.tif"))
crop_res_weighted <- weighted.mean(crop_res, crop_prop, na.rm = T)
crop_res_weighted
plotcrop_res_weighted
.libPaths(c(.libPaths()[2], .libPaths()[3]))
# avoid scientific notation
options(scipen = 999)
# Load libraries
library(raster)
library(stars)
rasterOptions(maxmemory = 5e+20) # 6e+10 ~51GB allowed
